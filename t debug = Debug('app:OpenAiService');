[1mdiff --git a/src/llm/openai/OpenAiService.ts b/src/llm/openai/OpenAiService.ts[m
[1mindex 4a05958..98e6e62 100644[m
[1m--- a/src/llm/openai/OpenAiService.ts[m
[1m+++ b/src/llm/openai/OpenAiService.ts[m
[36m@@ -1,5 +1,6 @@[m
 import Debug from 'debug';[m
[31m-import { Configuration, OpenAIApi } from 'openai';[m
[32m+[m[32mimport { Configuration } from 'openai';[m
[32m+[m[32mimport { OpenAI } from 'openai';  // Updated import based on the package[m
 import { LlmService } from '@src/llm/interfaces/LlmService';[m
 import { buildChatCompletionRequestBody } from '@src/llm/openai/operations/buildChatCompletionRequestBody';[m
 import { sendRequest } from '@src/llm/openai/operations/sendRequest';[m
[36m@@ -7,33 +8,16 @@[m [mimport ConfigurationManager from '@src/common/config/ConfigurationManager';[m
 [m
 const debug = Debug('app:OpenAiService');[m
 [m
[31m-/**[m
[31m- * OpenAiService Class[m
[31m- *[m
[31m- * This service integrates with the OpenAI API, allowing the bot to generate responses[m
[31m- * using OpenAI's models. It handles the communication with the API, including request[m
[31m- * preparation, sending, and response processing.[m
[31m- *[m
[31m- * Key Features:[m
[31m- * - API Key management and initialization[m
[31m- * - Request body building and response processing[m
[31m- * - Error handling and logging[m
[31m- */[m
 export class OpenAiService implements LlmService {[m
   private static instance: OpenAiService;[m
[31m-  private api: OpenAIApi;[m
[32m+[m[32m  private api: OpenAI;[m
   private isProcessing: boolean = false;[m
 [m
   private constructor(apiKey: string) {[m
     const configuration = new Configuration({ apiKey });[m
[31m-    this.api = new OpenAIApi(configuration);[m
[32m+[m[32m    this.api = new OpenAI(configuration);  // Updated to match the latest API[m
   }[m
 [m
[31m-  /**[m
[31m-   * Gets the singleton instance of OpenAiService.[m
[31m-   * @param apiKey The API key for authenticating with OpenAI.[m
[31m-   * @returns The singleton instance of OpenAiService.[m
[31m-   */[m
   public static getInstance(apiKey: string): OpenAiService {[m
     if (!OpenAiService.instance) {[m
       OpenAiService.instance = new OpenAiService(apiKey);[m
[36m@@ -41,12 +25,7 @@[m [mexport class OpenAiService implements LlmService {[m
     return OpenAiService.instance;[m
   }[m
 [m
[31m-  /**[m
[31m-   * Builds the request body for the OpenAI API.[m
[31m-   * @param historyMessages The input history messages for generating a response.[m
[31m-   * @returns The built request body.[m
[31m-   */[m
[31m-  buildChatCompletionRequestBody(historyMessages: any[]): Promise<object> {[m
[32m+[m[32m  public async buildChatCompletionRequestBody(historyMessages: any[]): Promise<object> {[m
     if (!Array.isArray(historyMessages)) {[m
       debug('Invalid input: historyMessages must be an array');[m
       throw new Error('Invalid input: historyMessages must be an array');[m
[36m@@ -56,58 +35,43 @@[m [mexport class OpenAiService implements LlmService {[m
     return buildChatCompletionRequestBody(historyMessages);[m
   }[m
 [m
[31m-  /**[m
[31m-   * Indicates that history is required for chat completions.[m
[31m-   * @returns True since the OpenAI API requires history in chat completion requests.[m
[31m-   */[m
[31m-  requiresHistory(): boolean {[m
[32m+[m[32m  public requiresHistory(): boolean {[m
     return true;[m
   }[m
 [m
[31m-  /**[m
[31m-   * Sends the request to the OpenAI API and processes the response.[m
[31m-   * @param requestBody The prepared request body.[m
[31m-   * @returns The API response.[m
[31m-   */[m
[31m-  async sendRequest(requestBody: object): Promise<any> {[m
[32m+[m[32m  public async sendRequest(requestBody: object): Promise<any> {[m
     if (!requestBody) {[m
       debug('No requestBody provided for sendRequest');[m
       return {};[m
     }[m
 [m
[31m-    debug('Sending request to OpenAI API with body: ' + JSON.stringify(requestBody));[m
[31m-    return sendRequest(this.api, requestBody);[m
[32m+[m[32m    const completeRequestBody = {[m
[32m+[m[32m      model: ConfigurationManager.LLM_MODEL,[m
[32m+[m[32m      messages: requestBody.messages,[m
[32m+[m[32m      max_tokens: ConfigurationManager.LLM_RESPONSE_MAX_TOKENS,[m
[32m+[m[32m      temperature: ConfigurationManager.LLM_TEMPERATURE,[m
[32m+[m[32m      top_p: ConfigurationManager.LLM_TOP_P,[m
[32m+[m[32m      frequency_penalty: ConfigurationManager.LLM_FREQUENCY_PENALTY,[m
[32m+[m[32m      presence_penalty: ConfigurationManager.LLM_PRESENCE_PENALTY,[m
[32m+[m[32m    };[m
[32m+[m
[32m+[m[32m    debug('Sending request to OpenAI API with body: ' + JSON.stringify(completeRequestBody));[m
[32m+[m[32m    return sendRequest(this.api, completeRequestBody);[m
   }[m
 [m
[31m-  /**[m
[31m-   * Checks if the service is currently processing a request.[m
[31m-   * @returns True if the service is processing, false otherwise.[m
[31m-   */[m
[31m-  isBusy(): boolean {[m
[32m+[m[32m  public isBusy(): boolean {[m
     return this.isProcessing;[m
   }[m
 [m
[31m-  /**[m
[31m-   * Sets the busy state of the service.[m
[31m-   * @param state The busy state to set.[m
[31m-   */[m
   public setBusy(state: boolean): void {[m
     this.isProcessing = state;[m
   }[m
 [m
[31m-  /**[m
[31m-   * Returns the OpenAIApi client instance.[m
[31m-   * @returns The OpenAIApi client.[m
[31m-   */[m
[31m-  public getClient(): OpenAIApi {[m
[32m+[m[32m  public getClient(): OpenAI {[m
     return this.api;[m
   }[m
 [m
[31m-  /**[m
[31m-   * Returns the model name used by the service.[m
[31m-   * @returns The model name.[m
[31m-   */[m
   public getModel(): string {[m
[31m-    return ConfigurationManager.LLM_MODEL; // Fetch from ConfigurationManager[m
[32m+[m[32m    return ConfigurationManager.LLM_MODEL;[m
   }[m
 }[m
